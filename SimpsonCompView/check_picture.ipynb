{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Программа Reboot 2020 поток 1 КУ Сбербанка\n",
    "### выполнил Малинкин Павел Борисович"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже код, который можно разместить на web сервере для демонстрации работы модели классификации героев мультсериала Симпсоны.\n",
    "Мне этого не удалось сделать из-за недостатка ресурсов на квоте Heroku для бесплатного использования,\n",
    "поэтому направляю код с описанием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка необходимых библиотек\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим класс, который использовался для обучения модели классификации\n",
    "class SimpsonsDataset(Dataset):\n",
    "    def __init__(self, files, mode):\n",
    "        super().__init__()\n",
    "        self.files = sorted(files)\n",
    "        # режим работы\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "\n",
    "        self.len_ = len(self.files)\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            self.labels = [path.parent.name for path in self.files]\n",
    "            self.label_encoder.fit(self.labels)\n",
    "\n",
    "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
    "                pickle.dump(self.label_encoder, le_dump_file)\n",
    "                      \n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "      \n",
    "    def augment(self, aug, image):\n",
    "        return aug(image=image)['image']\n",
    "        \n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        if self.mode == 'train':\n",
    "            image_np = np.array(image)       \n",
    "            image = Image.fromarray(self.augment(self.pil_transform(), image_np))\n",
    "        #image.save('out.jpg') - для проверки полученной картинки\n",
    "        return image\n",
    "\n",
    "    def pil_transform(self, p=1):    # дополнительная функция для албументации картинок\n",
    "        return Compose([\n",
    "                    albm.RandomResizedCrop(256, 256),  # растянем и вырежем центр картинки\n",
    "                    albm.OneOf([\n",
    "                        # apply one of transforms to 50% of images\n",
    "                        albm.RandomContrast(), # apply random contrast\n",
    "                        albm.RandomGamma(), # apply random gamma\n",
    "                        albm.RandomBrightness(), # apply random brightness\n",
    "                        albm.ShiftScaleRotate(),\n",
    "                        albm.ToGray(p=0.2),\n",
    "                        ],\n",
    "                        p = 0.5),            \n",
    "                    ])     \n",
    "  \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225],) \n",
    "        ])       \n",
    "        \n",
    "        x = self.load_sample(self.files[index])\n",
    "        # в метод load_sample добавлена албументация картинок\n",
    "        x = self._prepare_sample(x)\n",
    "        x = np.array(x / 255, dtype='float32')\n",
    "        x = transform(x)\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            return x, y\n",
    "        \n",
    "    def _prepare_sample(self, image):\n",
    "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
    "        return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
    "model = pickle.load(open(\"model_sim.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разные режимы датасета \n",
    "DATA_MODES = ['train', 'val', 'test']\n",
    "# все изображения будут масштабированы к размеру 224x224 px\n",
    "RESCALE_SIZE = 224\n",
    "# работаем на видеокарте\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Код для вызова работы модели для классификации картинки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_sample(model, inputs, device=DEVICE):\n",
    "    \"\"\"Предсказание, для одной картинки\"\"\"\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.to(device)\n",
    "        model.eval()\n",
    "        logit = model(inputs).cpu()\n",
    "        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([WindowsPath('11-15.jpg')], WindowsPath('11-15.jpg'))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Здесь нужно настроить путь для загрузки картинки\n",
    "from pathlib import Path\n",
    "file_name = '*.jpg'\n",
    "TEST_DIR = Path('./')\n",
    "test_files = sorted(list(TEST_DIR.rglob('11*.jpg')))\n",
    "# test_files = sorted(list(TEST_DIR.rglob(file_name)))  -- для загрузки по имени файла\n",
    "test_files, test_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.48265187e-13, 2.58478378e-11, 5.67217350e-15, 2.46068611e-14,\n",
       "        1.26102349e-11, 4.66464088e-17, 2.44028357e-11, 4.00723205e-12,\n",
       "        6.37014421e-13, 1.08802695e-14, 1.00041870e-16, 2.37735803e-10,\n",
       "        6.20240868e-18, 4.12101307e-15, 9.74560428e-16, 4.94226025e-13,\n",
       "        6.82803380e-12, 8.67903752e-12, 1.36900300e-11, 2.69721023e-14,\n",
       "        9.99999523e-01, 8.44414743e-08, 3.63426523e-07, 1.71800711e-13,\n",
       "        1.28971066e-13, 7.83665667e-12, 1.50577044e-12, 6.61074459e-11,\n",
       "        9.39939706e-12, 1.61960679e-14, 5.11391703e-14, 1.01770946e-12,\n",
       "        1.24517974e-11, 1.34014969e-15, 9.29729369e-17, 3.01203933e-14,\n",
       "        1.33565103e-11, 4.07608631e-08, 6.21267274e-11, 1.29471840e-14,\n",
       "        2.49465083e-17, 2.52829252e-13]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Преобразуем картинку для классификации\n",
    "val_dataset = SimpsonsDataset(test_files, mode='val')\n",
    "ex_img, true_label = val_dataset[0]\n",
    "probs_im = predict_one_sample(model, ex_img.unsqueeze(0))\n",
    "probs_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Классифицируем картинку\n",
    "y_pred = np.argmax(probs_im,-1)\n",
    "y_pred_ls = [label_encoder.classes_[i] for i in y_pred]\n",
    "label_classes = list(label_encoder.classes_)\n",
    "preds_class = [label_classes.index(i) for i in y_pred_ls]\n",
    "preds_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lisa_simpson'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Найдем имя персонажа\n",
    "label_classes[preds_class[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
